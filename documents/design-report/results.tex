\chapter{Results}
\label{results}

\section{Pre-processing Input Images}
Our initial plan was to use a geometric based and appearance based approach to pre process the input images before doing the shape modeling step. The geometric based approach involves doing edge detection on the image, which can highlight the contours of the lips better for easier detection. The appearance based approach involves doing color segmentation on the image which can separate the lips from the rest of the face due to their different color. 

After trying these approaches, we found that they are not viable methods of enhancement. The edge detection alone did not slow down the program noticeably (it only added 10 milliseconds of processing time per frame) but it made detection much worse. The shape modeling algorithm could not find landmarks on the input image after an edge detection filter was applied to it. The color segmentation filter did not worsen the shape modeling algorithm like edge detection did, but it also did not noticeably improve shape modeling either. Also, as a downside, doing color segmentation alone takes a noticeable amount of time (40 milliseconds per frame), so it slowed down the program considerably. And finally, combining the edge detection with color segmentation simply resulted in having both of their negative effects. As a result, we have decided that have no pre-processing step is the best choice for this application. The current architectural diagram for the system can be seen in \Cref{fig:architecture-new}.

\section{Mouth vs Face Detection}
Initially, we tried to detect and track only the mouth in the video feed. To do this, we used a statistical model that only had mouth points and a Haar Cascade design to detect a mouth. This process sometimes worked, but it ended up being too inaccurate since the Haar Cascade often narrowed the image down to the wrong area during the initial detection attempt. The initial detection is a crucial part of this tracking method, so it was important for us to find a way to make sure it succeeded as often a possible.

Given the inefficiency of focusing on only the mouth, we then tried detecting the entire face with a full face model and a face Haar Cascade. This proved to be far more accurate than our attempts to detect the mouth by itself. This is because a face has more distinct landmarks which allow for more accurate detection. Once the detection finishes, we just throw away the points that are not relevant to the lips.

\section{Face Detection Issues}
Since we are detecting an entire face, instead of just the lips in the video frames, some problems can occur depending on the user. For example, users with glasses can slightly skew the detection, since the model cannot find the eyes. However, this rarely causes problems with detecting the lips in the frames. One issue that does causes problems with lip detection is facial hair. If the user has a mustache or a beard, it is very likely that the lip contours will be wrong. The detector will think the top of the mustache is the upper lip.

\section{GPU-Complications}
We encountered a number of complications when attempting to convert our CPU code into a GPU implementation. The first difficulty is that transferring image data between the CPU and GPU is a fairly expensive procedure. When we first got the code running on the GPU it was running at less than one frame per second because it took so long to transfer images. We were able to move some more of the code onto the GPU so that there would be fewer image transfers over all, which brought the speed back up to a measurable rate of around 6 frames per second on the Tegra K1, but this still is not anywhere near being an improvement on the CPU speeds.

We found that the reason the GPU implementation is slower than the CPU implementation is due to the matchTemplate function. We use this function for each patch to fit the model to the target image. Usually, this function would be faster on the GPU since it tries to match the patch in every location on the target image simultaneously. However, our CPU implementation is highly optimized and for each 11x11 pixel patch, matchTemplate only searches a 16x16 pixel area. Thus, it is much faster to run matchTemplate on the CPU since it is only searching a few locations.

Lastly, the version of OpenCV with which we were working also did not support certain functions that we needed for and ideal implementation and we were forced to write our own. One example of this is the gemm function used for performing matrix multiplication on the GPU.

\section{Conclusion}
Despite the issues we have on the GPU, our CPU implementation is running at around 12 frames per second on the Tegra K1. This is 